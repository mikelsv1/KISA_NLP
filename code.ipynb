{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <h1><b>Scattertext applied to Hyperpartisan News Detection</b></h1>\n",
    "    <h3><b>Authors:</b> Julen Rodriguez and Mikel Salvoch</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy under 2.x could be required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scattertext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scattertext as st\n",
    "import spacy\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data\n",
    "Assemble the data to analyze into a Pandas data frame. It should have at least two columns, the text you'd like to analyze, and the category to study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hyperpartisan\\articles-training-byarticle-20181122.tsv\n",
    "convention_df = pd.read_csv('articles-training-byarticle-20181122.tsv', sep='\\t')\n",
    "# non header, first column: 1 for hyperpartisan, 0 for non-hyperpartisan\n",
    "convention_df.columns = ['hyperpartisan', 'article']\n",
    "convention_df['hyperpartisan'] = convention_df['hyperpartisan'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperpartisan</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>Trump Just Woke Up &amp; Viciously Attacked Puerto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>Liberals wailing about gun control, but what a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Laremy Tunsil joins NFL players in kneeling du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>It's 1968 All Over Again  Almost a half-centur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>Gold Price in December 2017 - Myriads of Signa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hyperpartisan                                            article\n",
       "0           True  Trump Just Woke Up & Viciously Attacked Puerto...\n",
       "1           True  Liberals wailing about gun control, but what a...\n",
       "2           True  Laremy Tunsil joins NFL players in kneeling du...\n",
       "3          False  It's 1968 All Over Again  Almost a half-centur...\n",
       "4           True  Gold Price in December 2017 - Myriads of Signa..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Load data into Scattertext corpus\n",
    "Turn the data frame into a Scattertext Corpus to begin analyzing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn it into a Scattertext Corpus \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "corpus = st.CorpusFromPandas(convention_df, \n",
    "                             category_col='hyperpartisan',\n",
    "                             text_col='article',\n",
    "                             nlp=nlp).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the terms that differentiate the corpus from a general English corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trump', 'twitter', 'obama', 'comey', 'tweeted', 'bannon', 'facebook', 'barack', 'hillary', 'kaepernick']\n"
     ]
    }
   ],
   "source": [
    "print(list(corpus.get_scaled_f_scores_vs_background().index[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the terms that are most associated with Hyperpartisan news:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the left',\n",
      " 'class',\n",
      " 'israel',\n",
      " 'ruling',\n",
      " 'china',\n",
      " 'conservative',\n",
      " 'ruling class',\n",
      " 'the ruling',\n",
      " 'he ’s',\n",
      " 'the media']\n"
     ]
    }
   ],
   "source": [
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['hyperpartisan Score'] = corpus.get_scaled_f_scores('True')\n",
    "pprint(list(term_freq_df.sort_values(by='hyperpartisan Score', ascending=False).index[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the terms that are most associated with non-Hyperpartisan news:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['send free',\n",
      " '|',\n",
      " '⚪',\n",
      " 'california ca',\n",
      " '⠀',\n",
      " 'hurricane',\n",
      " 'august',\n",
      " 'angeles',\n",
      " 'los angeles',\n",
      " 'los']\n"
     ]
    }
   ],
   "source": [
    "term_freq_df['non-hyperpartisan Score'] = corpus.get_scaled_f_scores('False')\n",
    "pprint(list(term_freq_df.sort_values(by='non-hyperpartisan Score', ascending=False).index[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Visualizing term associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='True',\n",
    "    category_name='Hyperpartisan',\n",
    "    not_category_name='Non-Hyperpartisan',\n",
    "    width_in_pixels=1000,\n",
    "    metadata=convention_df['hyperpartisan']\n",
    ")\n",
    "with open(\"Convention-Visualization.html\", 'wb') as file:\n",
    "    file.write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Visualizing Phrase associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytextrank\n",
      "  Downloading pytextrank-3.3.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting GitPython>=3.1 (from pytextrank)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: graphviz>=0.13 in d:\\anaconda\\lib\\site-packages (from pytextrank) (0.20.1)\n",
      "Collecting icecream>=2.1 (from pytextrank)\n",
      "  Downloading icecream-2.1.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: networkx>=2.6 in d:\\anaconda\\lib\\site-packages (from networkx[default]>=2.6->pytextrank) (3.2.1)\n",
      "Requirement already satisfied: pygments>=2.7.4 in d:\\anaconda\\lib\\site-packages (from pytextrank) (2.15.1)\n",
      "Requirement already satisfied: scipy>=1.7 in d:\\anaconda\\lib\\site-packages (from pytextrank) (1.13.1)\n",
      "Requirement already satisfied: spacy>=3.0 in d:\\anaconda\\lib\\site-packages (from pytextrank) (3.8.3)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython>=3.1->pytextrank)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: colorama>=0.3.9 in d:\\anaconda\\lib\\site-packages (from icecream>=2.1->pytextrank) (0.4.6)\n",
      "Collecting executing>=2.1.0 (from icecream>=2.1->pytextrank)\n",
      "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: asttokens>=2.0.1 in d:\\anaconda\\lib\\site-packages (from icecream>=2.1->pytextrank) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.22 in d:\\anaconda\\lib\\site-packages (from networkx[default]>=2.6->pytextrank) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.5 in d:\\anaconda\\lib\\site-packages (from networkx[default]>=2.6->pytextrank) (3.9.2)\n",
      "Requirement already satisfied: pandas>=1.4 in d:\\anaconda\\lib\\site-packages (from networkx[default]>=2.6->pytextrank) (2.2.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (3.1.4)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\anaconda\\lib\\site-packages (from spacy>=3.0->pytextrank) (3.5.0)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from asttokens>=2.0.1->icecream>=2.1->pytextrank) (1.16.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=3.1->pytextrank)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\anaconda\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.0->pytextrank) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.5->networkx[default]>=2.6->pytextrank) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.5->networkx[default]>=2.6->pytextrank) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.5->networkx[default]>=2.6->pytextrank) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.5->networkx[default]>=2.6->pytextrank) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.5->networkx[default]>=2.6->pytextrank) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.5->networkx[default]>=2.6->pytextrank) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.5->networkx[default]>=2.6->pytextrank) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.5->networkx[default]>=2.6->pytextrank) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas>=1.4->networkx[default]>=2.6->pytextrank) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas>=1.4->networkx[default]>=2.6->pytextrank) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0->pytextrank) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in d:\\anaconda\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy>=3.0->pytextrank) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\anaconda\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy>=3.0->pytextrank) (0.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\anaconda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0->pytextrank) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\anaconda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0->pytextrank) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\anaconda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0->pytextrank) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->spacy>=3.0->pytextrank) (2.1.3)\n",
      "Collecting numpy>=1.22 (from networkx[default]>=2.6->pytextrank)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\anaconda\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.5->networkx[default]>=2.6->pytextrank) (3.21.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in d:\\anaconda\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.0->pytextrank) (1.2.1)\n",
      "Requirement already satisfied: wrapt in d:\\anaconda\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.0->pytextrank) (1.17.0)\n",
      "Downloading pytextrank-3.3.0-py3-none-any.whl (26 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading icecream-2.1.4-py3-none-any.whl (14 kB)\n",
      "Downloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, numpy, executing, icecream, gitdb, GitPython, pytextrank\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Acceso denegado: 'd:\\\\anaconda\\\\lib\\\\site-packages\\\\numpy\\\\_core\\\\_multiarray_tests.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !pip install --user pytextrank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperpartisan</th>\n",
       "      <th>article</th>\n",
       "      <th>parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>Trump Just Woke Up &amp; Viciously Attacked Puerto...</td>\n",
       "      <td>(Trump, Just, Woke, Up, &amp;, Viciously, Attacked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>Liberals wailing about gun control, but what a...</td>\n",
       "      <td>(Liberals, wailing, about, gun, control, ,, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Laremy Tunsil joins NFL players in kneeling du...</td>\n",
       "      <td>(Laremy, Tunsil, joins, NFL, players, in, knee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>It's 1968 All Over Again  Almost a half-centur...</td>\n",
       "      <td>(It, 's, 1968, All, Over, Again,  , Almost, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>Gold Price in December 2017 - Myriads of Signa...</td>\n",
       "      <td>(Gold, Price, in, December, 2017, -, Myriads, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hyperpartisan                                            article  \\\n",
       "0           True  Trump Just Woke Up & Viciously Attacked Puerto...   \n",
       "1           True  Liberals wailing about gun control, but what a...   \n",
       "2           True  Laremy Tunsil joins NFL players in kneeling du...   \n",
       "3          False  It's 1968 All Over Again  Almost a half-centur...   \n",
       "4           True  Gold Price in December 2017 - Myriads of Signa...   \n",
       "\n",
       "                                               parse  \n",
       "0  (Trump, Just, Woke, Up, &, Viciously, Attacked...  \n",
       "1  (Liberals, wailing, about, gun, control, ,, bu...  \n",
       "2  (Laremy, Tunsil, joins, NFL, players, in, knee...  \n",
       "3  (It, 's, 1968, All, Over, Again,  , Almost, a,...  \n",
       "4  (Gold, Price, in, December, 2017, -, Myriads, ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\scattertext\\termscoring\\ScaledFScore.py:136: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = (cat_word_counts * 1. / (cat_word_counts + not_cat_word_counts))\n"
     ]
    }
   ],
   "source": [
    "import pytextrank\n",
    "\n",
    "# nlp.add_pipe(\"textrank\", last=True)\n",
    "\n",
    "convention_df = convention_df.assign(\n",
    "    parse=lambda df: df.article.apply(nlp),\n",
    "    # we label as hyperpartisan and non_hyperpartisan to avoid problems with True and False reserved words\n",
    "    hyperpartisan=lambda df: df.hyperpartisan.apply(lambda x: 'hyperpartisan' if x else 'non_hyperpartisan')\n",
    ")\n",
    "corpus = st.CorpusFromParsedDocuments(\n",
    "    convention_df,\n",
    "    category_col='hyperpartisan',\n",
    "    parsed_col='parse',\n",
    "    feats_from_spacy_doc=st.PyTextRankPhrases()\n",
    ").build(\n",
    ").compact(\n",
    "    st.AssociationCompactor(2000, use_non_text_features=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the terms present in the corpus are named entities, and, as opposed to frequency counts, their scores are the eigencentrality scores assigned to them by the TextRank algorithm. Running ```corpus.get_metadata_freq_df('')``` will return, for each category, the sums of terms' TextRank scores. The dense ranks of these scores will be used to construct the scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            hyperpartisan  non_hyperpartisan\n",
      "term                                                        \n",
      "Puerto Rican people              0.104552           0.000000\n",
      "Donald Trump                    22.772139          24.630074\n",
      "Puerto Rican                     0.468275           0.000000\n",
      "Trump                          125.671835          88.974905\n",
      "Puerto Rico                      3.506832           0.511172\n",
      "...                                   ...                ...\n",
      "the stomach                      0.013283           0.000000\n",
      "another interview                0.013148           0.000000\n",
      "his depravity                    0.012987           0.000000\n",
      "F**                              0.009696           0.000000\n",
      "And possibly tranquilizers       0.005146           0.000000\n",
      "\n",
      "[49258 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "term_category_scores = corpus.get_metadata_freq_df('')\n",
    "print(term_category_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we construct the plot, let's some helper variables Since the aggregate TextRank scores aren't particularly interpretable, we'll display the per-category rank of each score in the metadata_description field. These will be displayed after a term is clicked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_ranks = pd.DataFrame(\n",
    "    np.argsort(np.argsort(-term_category_scores, axis=0), axis=0) + 1,\n",
    "    columns=term_category_scores.columns,\n",
    "    index=term_category_scores.index)\n",
    "\n",
    "metadata_descriptions = {\n",
    "    term: '<br/>' + '<br/>'.join(\n",
    "        '<b>%s</b> TextRank score rank: %s/%s' % (cat, term_ranks.loc[term, cat], corpus.get_num_metadata())\n",
    "        for cat in corpus.get_categories())\n",
    "    for term in corpus.get_metadata()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_specific_prominence = term_category_scores.apply(\n",
    "    lambda r: r.hyperpartisan if r.hyperpartisan > r.non_hyperpartisan else -r.non_hyperpartisan,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed to construct the plot defining an html file to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='hyperpartisan',\n",
    "    not_category_name='non_hyperpartisan',\n",
    "    minimum_term_frequency=0,\n",
    "    pmi_threshold_coefficient=0,\n",
    "    width_in_pixels=1000,\n",
    "    transform=st.dense_rank,\n",
    "    metadata=corpus.get_df()['hyperpartisan'],\n",
    "    scores=category_specific_prominence,\n",
    "    sort_by_dist=False,\n",
    "    use_non_text_features=True,\n",
    "    topic_model_term_lists={term: [term] for term in corpus.get_metadata()},\n",
    "    topic_model_preview_size=0,\n",
    "    metadata_descriptions=metadata_descriptions,\n",
    "    use_full_doc=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"Convention-Visualization-TextRank.html\", 'wb') as file:\n",
    "    file.write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Visualizing Empath topics and categories\n",
    "\n",
    "In order to visualize Empath (Fast et al., 2016) topics and categories instead of terms, we'll need to create a Corpus of extracted topics and categories rather than unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperpartisan</th>\n",
       "      <th>article</th>\n",
       "      <th>parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperpartisan</td>\n",
       "      <td>Trump Just Woke Up &amp; Viciously Attacked Puerto...</td>\n",
       "      <td>(Trump, Just, Woke, Up, &amp;, Viciously, Attacked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hyperpartisan</td>\n",
       "      <td>Liberals wailing about gun control, but what a...</td>\n",
       "      <td>(Liberals, wailing, about, gun, control, ,, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hyperpartisan</td>\n",
       "      <td>Laremy Tunsil joins NFL players in kneeling du...</td>\n",
       "      <td>(Laremy, Tunsil, joins, NFL, players, in, knee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non_hyperpartisan</td>\n",
       "      <td>It's 1968 All Over Again  Almost a half-centur...</td>\n",
       "      <td>(It, 's, 1968, All, Over, Again,  , Almost, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hyperpartisan</td>\n",
       "      <td>Gold Price in December 2017 - Myriads of Signa...</td>\n",
       "      <td>(Gold, Price, in, December, 2017, -, Myriads, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hyperpartisan                                            article  \\\n",
       "0      hyperpartisan  Trump Just Woke Up & Viciously Attacked Puerto...   \n",
       "1      hyperpartisan  Liberals wailing about gun control, but what a...   \n",
       "2      hyperpartisan  Laremy Tunsil joins NFL players in kneeling du...   \n",
       "3  non_hyperpartisan  It's 1968 All Over Again  Almost a half-centur...   \n",
       "4      hyperpartisan  Gold Price in December 2017 - Myriads of Signa...   \n",
       "\n",
       "                                               parse  \n",
       "0  (Trump, Just, Woke, Up, &, Viciously, Attacked...  \n",
       "1  (Liberals, wailing, about, gun, control, ,, bu...  \n",
       "2  (Laremy, Tunsil, joins, NFL, players, in, knee...  \n",
       "3  (It, 's, 1968, All, Over, Again,  , Almost, a,...  \n",
       "4  (Gold, Price, in, December, 2017, -, Myriads, ...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install empath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_builder = st.FeatsFromOnlyEmpath()\n",
    "empath_corpus = st.CorpusFromParsedDocuments(convention_df,\n",
    "                                             category_col='hyperpartisan',\n",
    "                                             feats_from_spacy_doc=feat_builder,\n",
    "                                             parsed_col='parse').build()\n",
    "html = st.produce_scattertext_explorer(empath_corpus,\n",
    "                                       category='hyperpartisan',\n",
    "                                       category_name='Hyperpartisan',\n",
    "                                       not_category_name='Non-Hyperpartisan',\n",
    "                                       width_in_pixels=1000,\n",
    "                                       metadata=convention_df['hyperpartisan'],\n",
    "                                       use_non_text_features=True,\n",
    "                                       use_full_doc=True,\n",
    "                                       topic_model_term_lists=feat_builder.get_top_model_term_lists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Convention-Visualization-Empath.html\", 'wb') as file:\n",
    "    file.write(html.encode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
